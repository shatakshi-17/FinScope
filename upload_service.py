"""
Upload Service - Document Lifecycle Manager

This service manages the complete lifecycle of uploaded documents:
- Saves original files to MongoDB (using GridFS for large files)
- Processes TXT files with line markers for Gemini citation accuracy
- Converts PDF files to Markdown format
- Stores processed content and metadata in MongoDB

This service is independent and does NOT call the Gemini API.
"""

import os
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, List
from gridfs import GridFS
from bson import ObjectId

# Import database service
try:
    import db_service
except ImportError:
    raise ImportError("db_service is required. Please ensure db_service.py is available.")

# MongoDB collection name for uploaded documents
UPLOADS_COLLECTION = "uploaded_documents"


def get_uploads_collection():
    """
    Returns the MongoDB collection for uploaded documents.
    
    Returns:
        Collection: MongoDB collection instance
    """
    db = db_service.get_database()
    return db[UPLOADS_COLLECTION]


def get_gridfs():
    """
    Returns GridFS instance for storing large files.
    
    Returns:
        GridFS: GridFS instance for the database
    """
    db = db_service.get_database()
    return GridFS(db, collection="uploaded_files")


def process_txt_file_content(text_content: str) -> str:
    """
    Processes TXT content by adding line markers [L1], [L2], etc. to each line.
    This format matches what Gemini expects for accurate citations.
    
    Args:
        text_content: The text content to process
    
    Returns:
        str: Processed content with line markers
    """
    lines = text_content.splitlines(keepends=False)
    
    # Prepend every line with [L{line_number}] marker
    numbered_lines = []
    for line_num, line in enumerate(lines, start=1):
        # Preserve the line content but add the marker
        numbered_lines.append(f"[L{line_num}] {line}")
    
    return "\n".join(numbered_lines)


def process_pdf_file(file_path: str) -> str:
    """
    Converts a PDF file to Markdown format using pymupdf4llm.
    This preserves tables and formatting better than plain text extraction.
    
    Args:
        file_path: Path to the PDF file to process
    
    Returns:
        str: Markdown content from the PDF
    
    Raises:
        FileNotFoundError: If the file doesn't exist
        ImportError: If pymupdf4llm is not installed
        ValueError: If the PDF is image-based (scanned) with no extractable text
    """
    try:
        from pymupdf4llm import to_markdown
        import pymupdf
    except ImportError:
        raise ImportError(
            "pymupdf4llm is required for PDF processing. "
            "Install it with: pip install pymupdf4llm"
        )
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")
    
    # Try converting PDF to Markdown using file path
    markdown_text = to_markdown(file_path)
    
    # Check if result is empty (common with image-based/scanned PDFs)
    if not markdown_text or len(markdown_text.strip()) == 0:
        # Try opening the document and checking if it has extractable text
        doc = pymupdf.open(file_path)
        total_text_length = 0
        for page_num in range(len(doc)):
            page_text = doc[page_num].get_text()
            total_text_length += len(page_text.strip())
        doc.close()
        
        if total_text_length == 0:
            raise ValueError(
                f"PDF appears to be image-based (scanned) with no extractable text. "
                f"The file '{file_path}' contains {len(pymupdf.open(file_path))} pages, "
                f"but no text could be extracted. "
                f"OCR (Optical Character Recognition) would be required to process this PDF."
            )
        else:
            # Has text but to_markdown returned empty - try using document object
            doc = pymupdf.open(file_path)
            markdown_text = to_markdown(doc)
            doc.close()
            
            if not markdown_text or len(markdown_text.strip()) == 0:
                raise ValueError(
                    f"PDF conversion returned empty result despite having extractable text. "
                    f"This may indicate an issue with the PDF format or pymupdf4llm processing."
                )
    
    return markdown_text


def clean_markdown_table(markdown_text: str) -> str:
    """
    Post-processes Markdown to clean up messy tables generated by pymupdf4llm.
    
    Fixes:
    - Removes generic headers like Col2, Col3, Col4 from table headers
    - Removes <br>, ~~, and \n inside table cells, replacing with single space
    - Ensures all table rows have the same number of columns
    - Removes stray characters like ~~ or O markers
    - Ensures tables follow strict Markdown format without HTML tags
    
    Args:
        markdown_text: Raw Markdown text from pymupdf4llm
    
    Returns:
        str: Cleaned Markdown text with properly formatted tables
    """
    lines = markdown_text.split('\n')
    cleaned_lines = []
    i = 0
    
    while i < len(lines):
        line = lines[i]
        
        # Check if this line is part of a table (starts and ends with |)
        if line.strip().startswith('|') and line.strip().endswith('|'):
            # Found a table - collect all table lines
            table_lines = []
            while i < len(lines) and (lines[i].strip().startswith('|') or lines[i].strip() == ''):
                if lines[i].strip().startswith('|'):
                    table_lines.append(lines[i])
                elif lines[i].strip() == '' and len(table_lines) > 0:
                    # Empty line might be end of table, but check next line
                    if i + 1 < len(lines) and lines[i + 1].strip().startswith('|'):
                        # Next line is also a table line, so this empty line is part of table
                        table_lines.append(lines[i])
                    else:
                        # Next line is not a table, so we're done with this table
                        break
                i += 1
            
            # Process the table
            if len(table_lines) > 0:
                cleaned_table = _clean_table_block(table_lines)
                cleaned_lines.extend(cleaned_table)
                # Don't increment i here, the while loop already did
                continue
        else:
            # Not a table line, keep as-is
            cleaned_lines.append(line)
        
        i += 1
    
    return '\n'.join(cleaned_lines)


def _clean_table_block(table_lines: List[str]) -> List[str]:
    """
    Cleans a single table block (header + separator + rows).
    
    Args:
        table_lines: List of lines that form a table
    
    Returns:
        List[str]: Cleaned table lines
    """
    if not table_lines:
        return []
    
    # Parse table rows
    rows = []
    for line in table_lines:
        stripped = line.strip()
        if stripped.startswith('|') and stripped.endswith('|'):
            # Split by | and clean up
            cells = [cell.strip() for cell in stripped.split('|')]
            # Remove empty first and last (from leading/trailing |)
            if cells and cells[0] == '':
                cells = cells[1:]
            if cells and cells[-1] == '':
                cells = cells[:-1]
            rows.append(cells)
    
    if not rows:
        return []
    
    # Identify separator row (usually contains only ---, :---, etc.)
    separator_idx = None
    for idx, row in enumerate(rows):
        if all(re.match(r'^:?-+:?$', cell.strip()) for cell in row if cell.strip()):
            separator_idx = idx
            break
    
    # Separate header and body
    if separator_idx is not None:
        header_row = rows[0] if rows else []
        body_rows = rows[separator_idx + 1:] if separator_idx < len(rows) - 1 else []
    else:
        # No separator found, treat first row as header
        header_row = rows[0] if rows else []
        body_rows = rows[1:]
    
    # Clean header: remove generic Col2, Col3, Col4, etc.
    cleaned_header = []
    for cell in header_row:
        cleaned_cell = _clean_cell(cell)
        # Remove generic column headers
        if re.match(r'^Col\d+$', cleaned_cell, re.IGNORECASE):
            cleaned_cell = ''  # Remove generic headers
        cleaned_header.append(cleaned_cell)
    
    # Clean body rows
    cleaned_body = []
    for row in body_rows:
        cleaned_row = [_clean_cell(cell) for cell in row]
        cleaned_body.append(cleaned_row)
    
    # Determine max columns across all rows
    max_cols = max(len(cleaned_header), max((len(row) for row in cleaned_body), default=0))
    
    # Pad all rows to have the same number of columns
    cleaned_header = _pad_row(cleaned_header, max_cols)
    cleaned_body = [_pad_row(row, max_cols) for row in cleaned_body]
    
    # Reconstruct table
    result = []
    
    # Header row
    if cleaned_header:
        header_line = '| ' + ' | '.join(cleaned_header) + ' |'
        result.append(header_line)
    
    # Separator row
    if separator_idx is not None:
        separator_line = '| ' + ' | '.join(['---'] * max_cols) + ' |'
        result.append(separator_line)
    
    # Body rows
    for row in cleaned_body:
        row_line = '| ' + ' | '.join(row) + ' |'
        result.append(row_line)
    
    return result


def _clean_cell(cell: str) -> str:
    """
    Cleans a single table cell by removing HTML tags, strikethrough markers, and normalizing whitespace.
    
    Args:
        cell: Raw cell content
    
    Returns:
        str: Cleaned cell content
    """
    if not cell:
        return ''
    
    # Remove HTML <br> tags (case insensitive)
    cell = re.sub(r'<br\s*/?>', ' ', cell, flags=re.IGNORECASE)
    
    # Remove strikethrough markers ~~
    cell = re.sub(r'~~', '', cell)
    
    # Remove stray O markers that appear alone (but keep O in words)
    cell = re.sub(r'\bO\b', '', cell)
    
    # Replace newlines and multiple spaces with single space
    cell = re.sub(r'\s+', ' ', cell)
    
    # Strip whitespace
    cell = cell.strip()
    
    return cell


def _pad_row(row: List[str], target_length: int) -> List[str]:
    """
    Pads a row to have exactly target_length columns.
    
    Args:
        row: List of cell values
        target_length: Desired number of columns
    
    Returns:
        List[str]: Padded row
    """
    if len(row) >= target_length:
        return row[:target_length]
    else:
        return row + [''] * (target_length - len(row))


def save_to_mongodb(
    original_filename: str,
    raw_content: bytes,
    processed_content: str,
    company_name: str,
    year: int,
    doc_type: str,
    file_type: str
) -> Dict[str, str]:
    """
    Saves document to MongoDB:
    - Raw file content (using GridFS for large files, direct storage for small text)
    - Processed content (stored as text in document)
    - Metadata (stored in document)
    
    Args:
        original_filename: Original filename
        raw_content: Raw file content as bytes
        processed_content: Processed content (TXT with line markers or PDF as Markdown)
        company_name: Name of the company
        year: Year of the document
        doc_type: Type of document (e.g., "10-K", "8-K", "upload")
        file_type: Either 'txt' or 'pdf'
    
    Returns:
        Dict with keys: document_id, raw_file_id, processed_content_id
    """
    collection = get_uploads_collection()
    fs = get_gridfs()
    
    upload_date = datetime.utcnow()
    
    # Determine if we should use GridFS (for files > 16MB or PDFs)
    use_gridfs = len(raw_content) > 16 * 1024 * 1024 or file_type == 'pdf'
    
    # Save raw file content
    if use_gridfs:
        # Use GridFS for large files
        raw_file_id = fs.put(
            raw_content,
            filename=original_filename,
            content_type=f"application/{file_type}" if file_type == 'pdf' else "text/plain"
        )
        raw_file_id_str = str(raw_file_id)
        raw_storage_type = "gridfs"
    else:
        # Store directly in document (for small text files)
        raw_file_id = None
        raw_file_id_str = None
        raw_storage_type = "embedded"
    
    # Create document with metadata and processed content
    document = {
        "original_filename": original_filename,
        "company_name": company_name,
        "year": year,
        "doc_type": doc_type,
        "file_type": file_type,
        "upload_date": upload_date,
        "processed_content": processed_content,
        "raw_storage_type": raw_storage_type,
        "raw_file_id": raw_file_id_str,  # GridFS file ID if using GridFS
        "raw_content": raw_content if not use_gridfs else None,  # Embedded content if not using GridFS
        "processed_content_length": len(processed_content),
        "raw_content_length": len(raw_content)
    }
    
    # Insert document
    result = collection.insert_one(document)
    document_id = str(result.inserted_id)
    
    print(f"✓ Saved to MongoDB: document_id={document_id}")
    if use_gridfs:
        print(f"✓ Raw file stored in GridFS: file_id={raw_file_id_str}")
    else:
        print(f"✓ Raw content embedded in document")
    
    return {
        "document_id": document_id,
        "raw_file_id": raw_file_id_str,
        "processed_content_length": len(processed_content),
        "raw_content_length": len(raw_content)
    }


def upload_file(
    file_path: str,
    company_name: str,
    year: int,
    doc_type: str = "upload"
) -> Dict[str, str]:
    """
    Main function to upload and process a document.
    Handles the complete lifecycle: read file, process, and save to MongoDB.
    
    Args:
        file_path: Path to the file to upload (TXT or PDF)
        company_name: Name of the company
        year: Year of the document
        doc_type: Type of document (default: "upload")
    
    Returns:
        Dict with keys: document_id, raw_file_id, processed_content_length, raw_content_length
    
    Raises:
        FileNotFoundError: If the source file doesn't exist
        ValueError: If the file type is not supported (only TXT and PDF) or
                    if the PDF is image-based (scanned) with no extractable text
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Source file not found: {file_path}")
    
    # Get file extension and validate
    file_ext = Path(file_path).suffix.lower()
    if file_ext not in ['.txt', '.pdf']:
        raise ValueError(f"Unsupported file type: {file_ext}. Only .txt and .pdf are supported.")
    
    # Get the original filename
    original_filename = os.path.basename(file_path)
    file_type = file_ext[1:]  # Remove the dot: '.txt' -> 'txt'
    
    # Step 1: Read raw file content
    print(f"✓ Reading file: {original_filename}")
    with open(file_path, 'rb') as f:
        raw_content = f.read()
    
    # Step 2: Process the file
    print(f"✓ Processing {file_type.upper()} file...")
    if file_ext == '.txt':
        # Read as text for processing
        with open(file_path, 'r', encoding='utf-8') as f:
            text_content = f.read()
        processed_content = process_txt_file_content(text_content)
    elif file_ext == '.pdf':
        processed_content = process_pdf_file(file_path)
        # Clean up messy tables in the Markdown
        processed_content = clean_markdown_table(processed_content)
    
    # Step 3: Save everything to MongoDB
    print(f"✓ Saving to MongoDB...")
    result = save_to_mongodb(
        original_filename=original_filename,
        raw_content=raw_content,
        processed_content=processed_content,
        company_name=company_name,
        year=year,
        doc_type=doc_type,
        file_type=file_type
    )
    
    return result


def normalize_file_path(path_input: str) -> str:
    """
    Normalizes a file path input by:
    - Stripping quotes (single or double)
    - Converting forward slashes to backslashes on Windows
    - Removing leading/trailing whitespace
    
    Args:
        path_input: Raw path input from user
    
    Returns:
        str: Normalized file path
    """
    # Strip quotes
    path = path_input.strip().strip('"').strip("'")
    
    # On Windows, convert forward slashes to backslashes for consistency
    # (though both work, backslashes are more standard)
    if os.name == 'nt':  # Windows
        path = path.replace('/', '\\')
    
    return path


def browse_for_file() -> Optional[str]:
    """
    Opens a file browser dialog to select a file.
    
    Returns:
        Optional[str]: Selected file path, or None if cancelled
    """
    try:
        import tkinter as tk
        from tkinter import filedialog
        
        # Create a root window and hide it
        root = tk.Tk()
        root.withdraw()  # Hide the main window
        root.attributes('-topmost', True)  # Bring to front
        
        # Open file dialog
        file_path = filedialog.askopenfilename(
            title="Select a file to upload (TXT or PDF)",
            filetypes=[
                ("All supported", "*.txt;*.pdf"),
                ("Text files", "*.txt"),
                ("PDF files", "*.pdf"),
                ("All files", "*.*")
            ]
        )
        
        root.destroy()
        return file_path if file_path else None
        
    except ImportError:
        print("  Note: tkinter not available. File browser disabled.")
        return None
    except Exception as e:
        print(f"  Note: Could not open file browser: {e}")
        return None


if __name__ == "__main__":
    """
    Terminal interface for the Upload Service.
    
    Allows interactive uploading of TXT and PDF files with metadata.
    """
    print("=" * 80)
    print("Upload Service - Terminal Interface")
    print("=" * 80)
    print("\nThis service manages document uploads:")
    print("  - TXT files: Adds line markers [L1], [L2], etc. for Gemini citation")
    print("  - PDF files: Converts to Markdown and cleans up messy tables")
    print("\nFiles are saved to MongoDB:")
    print(f"  - Collection: {UPLOADS_COLLECTION}")
    print("  - Raw files: Stored in GridFS (for large files) or embedded in documents")
    print("  - Processed content: Stored in document")
    print("  - Metadata: Stored in document")
    print("\n" + "=" * 80)
    print("TIP: To paste file path in PowerShell:")
    print("  - Right-click in the terminal window to paste")
    print("  - Or type the path manually")
    print("  - You can use quotes around the path if needed")
    print("=" * 80)
    print("\nType 'quit' or 'exit' to exit")
    
    while True:
        try:
            print("\n" + "-" * 80)
            
            # Get file path
            file_path_input = input("\nEnter file path (TXT or PDF) or 'browse' to use file browser: ").strip()
            
            if not file_path_input:
                continue
            
            if file_path_input.lower() in ['quit', 'exit', 'q']:
                print("\nGoodbye!")
                break
            
            # Handle file browser option
            if file_path_input.lower() in ['browse', 'b']:
                print("\nOpening file browser...")
                file_path = browse_for_file()
                if not file_path:
                    print("  No file selected. Continuing...")
                    continue
                print(f"  Selected: {file_path}")
            else:
                # Normalize the path (strip quotes, handle slashes)
                file_path = normalize_file_path(file_path_input)
            
            if not file_path:
                continue
            
            if file_path.lower() in ['quit', 'exit', 'q']:
                print("\nGoodbye!")
                break
            
            # Validate file exists
            if not os.path.exists(file_path):
                print(f"\n✗ Error: File not found: {file_path}")
                print("  Please check the path and try again.")
                print("  Tip: You can drag and drop the file into the terminal, or")
                print("       right-click in PowerShell to paste the path.")
                continue
            
            # Get company name
            company_name = input("Enter company name: ").strip()
            if not company_name:
                print("✗ Error: Company name is required")
                continue
            
            # Get year
            year_input = input("Enter year: ").strip()
            try:
                year = int(year_input)
            except ValueError:
                print("✗ Error: Year must be a number")
                continue
            
            # Get doc_type (optional)
            doc_type = input("Enter document type (press Enter for 'upload'): ").strip()
            if not doc_type:
                doc_type = "upload"
            
            # Upload the file
            print("\n" + "=" * 80)
            print("Processing file...")
            print("=" * 80)
            
            try:
                result = upload_file(file_path, company_name, year, doc_type)
                
                print("\n" + "=" * 80)
                print("✓ Upload Complete!")
                print("=" * 80)
                print(f"\nDocument saved to MongoDB:")
                print(f"  Document ID: {result['document_id']}")
                if result.get('raw_file_id'):
                    print(f"  Raw file (GridFS): {result['raw_file_id']}")
                else:
                    print(f"  Raw content: Embedded in document")
                print(f"  Processed content length: {result['processed_content_length']:,} characters")
                print(f"  Raw content length: {result['raw_content_length']:,} bytes")
                
            except ValueError as e:
                print(f"\n✗ Error: {e}")
            except FileNotFoundError as e:
                print(f"\n✗ Error: {e}")
            except ImportError as e:
                print(f"\n✗ Error: {e}")
            except Exception as e:
                print(f"\n✗ Unexpected error: {e}")
                import traceback
                traceback.print_exc()
        
        except KeyboardInterrupt:
            print("\n\nInterrupted. Goodbye!")
            break
        except EOFError:
            print("\n\nGoodbye!")
            break

